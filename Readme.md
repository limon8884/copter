Идея создать софт для мозга квадрокопрета основанное на RL.

Начнем с решения более простой задачи: есть стенд - палка с зафиксированной осью с 2 моторами на концах. 
Первый шаг - научиться балансировать ей, управляя моторами. То есть полный контроль на упрощенной моделью коптера.
Флоу работы: программируем виртуальную среду, обучаем RL-агента в ней, сохраняем агента локально на носитель (raspberry pi), который будет управлять стендом. В роли платы управления датчиками и моторами будет выступать ардуино.

Для симуляций написана библиотека Copter, содержащая следующие классы: 
Network.py - нейросеть, объект torch.nn. Именно ее будем обучать
TwoModelStick.py - Физическая модель 2-моторной палки с моторами. Впоследствии будет заменена на систему из 4 моторов на раме (коптера). Реализует симуляцию среды. На вход принимает сигналы на моторы, на выход выдает состояние среды.
Agent.py - промежуточное звено между сеткой и средой. Реализует коммуниказию, следуя (пока что) вшитой в него политике.
Session.py - класс для обучения агента в среде. Реализует несколько итераций одной сессии, собирает логи.

В ноутбуке main_note.ipynb класс Trainer_CEM реализует обучение нейросети кросс-энтропийным методом. Как только все баги будут исправлены, все фичи дописаны, класс будет вынесен в отдельный файл, а метод обучения будет использован более современный (например, D3QN)

Inference.py - класс, взаимодействующий со средой (непосредственно с ардуино) на инференсе. Реализует политику агента в online.
connecting.ino - бэкенд ардуино. Взаимодействует с носителем через serial порт. Управляет моторами, читает сигналы с датчиков.

Таминги со стороны агента можно описать так:
-get data
-computing action (t)
-send data
-waiting (60ms - t)

Тайминги со стороны arduino:
-read sensors data
-get data
-send data
-waiting

По замерам весь цикл со стороны ардуино занимает 60ms
