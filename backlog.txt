

1. Развести step_size: для env модельный, для agent - тот, который реально выдержит носитель
2. Релизнуть более секси-алгоритм, например, DQN
3. Зашумить тензоры                                                                                DONE
4. Перепридумать лоссы (в т.ч. max_reward)
5. Добавить логгирование upper_force                                                               DONE
6. Добавить третий вид action - "не изменять"                                                      DONE
7. Изменить генерацию upper_force на пошаговую                                                     DONE
8. Обобщить target_upper_force на target_params                                                    DONE
9. Написать класс PolicyMaker, возвращающий actions по выходу сети по какой-то политике
10. Написать класс Inference, реализующий взаимодействие обученной сетки с портом компа (ардуино)
11. Проверить, что модельные скорости это не зашумленные скорости
